# -*- coding: utf-8 -*-
"""Prediksi_Penyakit_Jantung.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1fFBtWbDbeTi7xLhRecHJB3hTUjYA4YJE

### Pemuatan Library dan Dataset

Pada cell di bawah ini, Proses mengimpor library yang dibutuhkan untuk analisis data dan machine learning, seperti pandas untuk manipulasi data, numpy untuk operasi numerik, serta matplotlib dan seaborn untuk visualisasi data.

Selanjutnya, dataset `heart.csv` yang berisi informasi pasien terkait penyakit jantung dimuat ke dalam DataFrame pandas bernama `df`. Fungsi `df.head()` digunakan untuk menampilkan lima baris pertama dari dataset guna mendapatkan gambaran umum tentang fitur-fitur yang ada dan format datanya.
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

# Load dataset
df = pd.read_csv('heart.csv')
df.head()

df.info()
print("\nMissing values per column:\n", df.isnull().sum())
df.describe()

"""### Pemeriksaan Informasi Dasar dan Nilai Hilang


**Hasil Observasi :**
- Dari output `df.info()`, diketahui dataset terdiri dari **918 baris dan 12 kolom**.
- Semua kolom memiliki tipe data yang sesuai (numerik atau objek/string).
- Berdasarkan `df.isnull().sum()`, **tidak ditemukan adanya nilai yang hilang (missing values)** pada setiap kolom dataset. Ini menunjukkan data cukup bersih dari sisi kelengkapan.
- `df.describe()` menunjukkan variasi rentang nilai antar fitur numerik, yang mengindikasikan perlunya penskalaan fitur (feature scaling) di tahap selanjutnya. Misalnya, 'Age' berkisar antara 28-77, sedangkan 'Oldpeak' berkisar antara -2.6 hingga 6.2.

### Melihat Sebaran Data untuk Fitur Angka

Setelah k melihat perbandingan jumlah pasien yang punya penyakit jantung dan yang tidak, sekarang kita ingin tahu lebih banyak tentang fitur-fitur lain yang berupa angka, misalnya usia, tekanan darah, kolesterol, dan lainnya. saya akan membuat gambar (histogram) untuk masing-masing fitur angka ini. Tujuannya adalah untuk melihat bagaimana sebaran nilai-nilai pada setiap fitur tersebut: apakah nilainya banyak yang berkumpul di tengah, atau lebih banyak di angka rendah, atau di angka tinggi. Ini juga bisa membantu kita melihat kalau ada angka-angka yang aneh atau sangat berbeda dari yang lain.

**Apa yang dilakukan:**
-   Mentukan dulu fitur-fitur angka mana saja yang ingin dilihat sebarannya. Dalam hal ini, kita memilih: 'Age' (Usia), 'RestingBP' (Tekanan Darah Istirahat), 'Cholesterol' (Kolesterol), 'MaxHR' (Denyut Jantung Maksimum), dan 'Oldpeak'.
-   Kemudian, saya menggunakan fungsi `.hist()` yang ada di Pandas untuk secara otomatis membuatkan gambar histogram untuk setiap fitur yang sudah kita pilih tadi. Setiap fitur akan punya gambar histogramnya sendiri.

**Mengapa dilakukan:**
-   Histogram ini seperti cermin yang menunjukkan bagaimana data tersebar untuk setiap fitur angka. hal ini dapat membantu mengetahui apakah kebanyakan pasien usianya muda atau tua, tekanan darahnya tinggi atau rendah, dan seterusnya.
-   Ini juga cara mudah untuk melihat kalau-kalau ada nilai yang sangat aneh, misalnya tekanan darah yang terlalu rendah atau kolesterol yang sangat tinggi.
-   Informasi ini bisa berguna nanti. Kalau misalnya ada fitur yang sebarannya sangat miring, atau ada angka-angka aneh, kita mungkin perlu melakukan penyesuaian tertentu sebelum data ini dipakai untuk membuat model prediksi.
"""

# Visualize target distribution
sns.countplot(x='HeartDisease', data=df)
plt.title('Distribution of Target (HeartDisease)')
plt.xlabel('HeartDisease (0 = No, 1 = Yes)')
plt.ylabel('Count')
plt.show()

"""**Hasil Observasi Distribusi Variabel Target:**

- Berdasarkan plot countplot yang dihasilkan, dapat dilihat distribusi jumlah pasien untuk setiap kategori dalam variabel `HeartDisease`.
- Terlihat bahwa terdapat **508 pasien yang terindikasi memiliki penyakit jantung (HeartDisease = 1)** dan **410 pasien yang tidak terindikasi memiliki penyakit jantung (HeartDisease = 0)**. Perbedaan jumlah antara kedua kelas adalah 98.
- Secara visual, dataset ini menunjukkan **sedikit ketidakseimbangan** ke arah kelas positif (HeartDisease = 1), namun perbedaan ini (sekitar 55.3% vs 44.7%) umumnya **tidak dianggap sebagai ketidakseimbangan kelas yang ekstrem**. Oleh karena itu, penanganan khusus seperti *resampling* mungkin tidak langsung diperlukan, tetapi metrik evaluasi yang robust terhadap sedikit ketidakseimbangan (seperti F1-score) akan tetap penting untuk dipertimbangkan saat mengevaluasi model.
"""

num_cols = ['Age', 'RestingBP', 'Cholesterol', 'MaxHR', 'Oldpeak']
df[num_cols].hist(figsize=(12,8))
plt.tight_layout()
plt.show()

"""**Hasil Pengamatan dari Gambar Sebaran Fitur Angka:**

Dari gambar-gambar histogram yang muncul untuk setiap fitur angka:

-   **Age (Usia):** Gambar sebaran usia pasien terlihat cukup seimbang, dengan kebanyakan pasien berada di usia paruh baya hingga lebih tua.
-   **RestingBP (Tekanan Darah Istirahat):** Sebagian besar pasien punya tekanan darah istirahat di sekitar angka 120-140. Tapi, ada juga beberapa data yang menunjukkan angka 0, yang sepertinya aneh untuk tekanan darah orang hidup. Ini perlu kita perhatikan.
-   **Cholesterol (Kolesterol):** Sama seperti tekanan darah, ada juga data kolesterol yang angkanya 0, ini juga aneh dan perlu diperiksa lebih lanjut. Untuk data lainnya, sebaran kolesterol cenderung lebih banyak di angka yang tidak terlalu tinggi, tapi ada juga yang nilainya cukup tinggi.
-   **MaxHR (Denyut Jantung Maksimum):** Sebaran denyut jantung maksimum pasien kelihatannya cukup normal, seperti bentuk lonceng, dengan kebanyakan pasien punya denyut jantung maksimum di sekitar 120-170 kali per menit.
-   **Oldpeak:** Untuk fitur ini, kebanyakan nilainya kecil, dekat dengan 0. Semakin ke kanan (nilai lebih besar), jumlah datanya semakin sedikit. Ini berarti sebarannya miring ke kanan.

**Conclusion**
-   Kita menemukan ada angka 0 yang aneh pada data `RestingBP` dan `Cholesterol`. Ini penting untuk diingat karena angka yang tidak masuk akal ini bisa mengganggu model prediksi kita nanti. Kita perlu memutuskan apa yang akan dilakukan dengan data ini (misalnya, diperbaiki atau mungkin dihapus jika memang salah).
-   Beberapa fitur seperti `Cholesterol` dan `Oldpeak` punya sebaran data yang agak miring. Ini juga perlu jadi catatan, karena kadang model komputer lebih suka data yang sebarannya lebih normal.
"""

# Correlation heatmap - Moved after encoding and scaling
plt.figure(figsize=(10, 8))
# Use the encoded DataFrame for correlation calculation
correlation_matrix = df_encoded.corr()
sns.heatmap(correlation_matrix, annot=True, fmt='.2f', cmap='coolwarm', square=True)
plt.title('Correlation Heatmap (After Encoding and Scaling)')
plt.show()

"""# Encoding

Beberapa fitur di data seperti 'Jenis Kelamin' atau 'Tipe Nyeri Dada', bentuknya bukan angka tapi kategori (teks). Oleh karena itu, kita perlu mengubahnya menjadi angka. Proses ini disebut *encoding*, dan menggunakan metode *One-Hot Encoding*.

**Apa yang dilakukan:**
-  Menggunakan fungsi `pd.get_dummies()` dari Pandas pada fitur-fitur kategori: 'Sex', 'ChestPainType', 'RestingECG', 'ExerciseAngina', dan 'ST_Slope'.
-   Setiap kategori dalam fitur tersebut diubah menjadi kolom baru yang isinya 0 atau 1. Opsi `drop_first=True` digunakan untuk membuat data lebih efisien.
-   Hasilnya disimpan dalam tabel baru `df_encoded`.

**Mengapa dilakukan:**
-   Agar semua data siap digunakan oleh model komputer.
-   *One-Hot Encoding* mengubah data kategori menjadi angka tanpa membuat komputer salah mengartikan adanya urutan antar kategori.
"""

df_encoded = pd.get_dummies(df, columns=['Sex', 'ChestPainType', 'RestingECG', 'ExerciseAngina', 'ST_Slope'], drop_first=True)
df_encoded.head()

"""**Hasil Pengamatan Setelah Encoding:**
-   Kolom-kolom yang tadinya berisi teks (misalnya 'Sex' dengan 'M' atau 'F') di tabel `df_encoded` kini telah berubah menjadi kolom-kolom baru berisi angka 0 atau 1.
-   Jumlah total kolom di tabel data menjadi lebih banyak.

# *Scaling*

Fitur-fitur angka di data kita (seperti 'Usia', 'Kolesterol') punya rentang nilai yang berbeda-beda. Perlu menyamakan skala angka-angka ini agar model optimal.

Apa yang dilakukan:

Memakai StandardScaler dari scikit-learn untuk fitur-fitur angka: 'Age', 'RestingBP', 'Cholesterol', 'MaxHR', dan 'Oldpeak'.
Proses ini mengubah nilai di setiap fitur tersebut sehingga rata-ratanya jadi sekitar 0 dan sebaran datanya (standar deviasi) jadi sekitar 1.
Kemudian membuat gambar histogram lagi untuk fitur-fitur yang baru saja disamakan skalanya ini, untuk melihat bagaimana tampilan sebaran datanya sekarang.
"""

from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
num_features = ['Age', 'RestingBP', 'Cholesterol', 'MaxHR', 'Oldpeak']
df_encoded[num_features] = scaler.fit_transform(df_encoded[num_features])


df_encoded[num_features].hist(figsize=(12,8))
plt.tight_layout()
plt.show()

"""Hasil Pengamatan dari Histogram (Setelah Scaling):

- angka-angka di sumbu horizontal (sumbu x) pada setiap histogram ini akan berbeda dari histogram sebelum scaling. Sekarang, nilai-nilainya akan berkisar di sekitar angka 0.
- Meskipun angka-angkanya berubah, bentuk umum dari sebaran data untuk setiap fitur (apakah miring, atau seperti lonceng) kemungkinan besar akan tetap mirip dengan sebelum di-scale. Yang berubah drastis adalah rentang nilainya.
- Ini menunjukkan bahwa fitur-fitur tersebut sekarang punya skala yang seragam, dengan rata-rata mendekati 0.

# *Splitting Data*

Data akan dibagi menjadi 2 Train dan Test dengan skema 80% training dan 20% testing
"""

from sklearn.model_selection import train_test_split

X = df_encoded.drop('HeartDisease', axis=1)
y = df_encoded['HeartDisease']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)
print("Train shape:", X_train.shape)
print("Test shape:", X_test.shape)

"""# *Training Model*
Saya mengambil model ***LogisticRegression*** dan ***RandomForestClassifier*** dari scikit-learn.

Regresi Logistik: Saya membuat model (logreg), mengatur max_iter=1000 (agar cukup "belajar") dan random_state=42 (untuk hasil konsisten), lalu melatihnya dengan logreg.fit(X_train, y_train).
Random Forest: Saya juga membuat model (rf), mengatur random_state=42, dan melatihnya dengan rf.fit(X_train, y_train).

Tujuan utama melatih (.fit()) adalah agar model menemukan pola dalam data latih untuk bisa membuat prediksi.
Saya memilih dua model berbeda untuk perbandingan:
Regresi Logistik: Model dasar yang sederhana dan cepat.
Random Forest: Model yang lebih canggih dan seringkali lebih akurat.
Setelah dilatih, kedua model ini siap untuk diuji kemampuannya pada data baru.
"""

from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier

# Logistic Regression
logreg = LogisticRegression(max_iter=1000, random_state=42)
logreg.fit(X_train, y_train)

# Random Forest
rf = RandomForestClassifier(random_state=42)
rf.fit(X_train, y_train)

"""# *Parameter Optimization*

Pada tahap ini, saya melakukan optimasi hyperparameter untuk model Random Forest. Tujuannya adalah untuk menemukan kombinasi pengaturan (hyperparameter) yang paling optimal agar model dapat memberikan kinerja prediksi terbaik. Proses ini menggunakan GridSearchCV, yang secara sistematis mencoba berbagai kombinasi pengaturan yang telah saya tentukan.

Dengan melakukan optimasi ini, saya berusaha meningkatkan kemampuan generalisasi model, sehingga model tidak hanya bagus pada data latih tetapi juga akurat ketika digunakan pada data baru, dan terhindar dari masalah seperti underfitting (model terlalu sederhana) atau overfitting (model terlalu kompleks dan hanya hafal data latih). Kinerja setiap kombinasi pengaturan dievaluasi berdasarkan F1-score melalui validasi silang pada data latih

"""

from sklearn.model_selection import GridSearchCV

param_grid = {
    'n_estimators': [50, 100, 200],
    'max_depth': [None, 5, 10],
    'min_samples_split': [2, 5, 10]
}
grid_rf = GridSearchCV(RandomForestClassifier(random_state=42), param_grid, cv=5, scoring='f1', n_jobs=-1)
grid_rf.fit(X_train, y_train)
print("Best params:", grid_rf.best_params_)
best_rf = grid_rf.best_estimator_

from sklearn.model_selection import GridSearchCV


logreg_base = LogisticRegression(random_state=42, max_iter=1000)


param_grid_lr = {
    'C': [0.01, 0.1, 1, 10, 100],
    'penalty': ['l2'],
    'solver': ['liblinear', 'lbfgs']
}


grid_lr = GridSearchCV(estimator=logreg_base,
                       param_grid=param_grid_lr,
                       cv=5,
                       scoring='f1',
                       n_jobs=-1)


grid_lr.fit(X_train, y_train)

print("Parameter terbaik untuk Logistic Regression:", grid_lr.best_params_)

best_logreg = grid_lr.best_estimator_

from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report

models = {
    'Logistic Regression': logreg,
    'Random Forest': rf,
    'Best Random Forest': best_rf
}

for name, model in models.items():
    y_pred = model.predict(X_test)
    print(f"=== {name} ===")
    print("Accuracy:", accuracy_score(y_test, y_pred))
    print("Precision:", precision_score(y_test, y_pred))
    print("Recall:", recall_score(y_test, y_pred))
    print("F1 Score:", f1_score(y_test, y_pred))
    print("Confusion Matrix:\n", confusion_matrix(y_test, y_pred))
    print(classification_report(y_test, y_pred))
    print()

"""**Kesimpulan Pemilihan Model dan Hasil Akhir Proyek**

Setelah melakukan analisis dan perbandingan kinerja dari semua model yang diuji (Logistic Regression, Random Forest standar, dan Random Forest yang telah dioptimasi) pada data uji, saya memutuskan bahwa **model Logistic Regression adalah solusi akhir yang paling optimal** untuk proyek prediksi penyakit jantung ini.

Ringkasan metrik performa utama dari **model Logistic Regression** pada data uji yang mendukung keputusan ini adalah:
-   Akurasi Keseluruhan: 0.886 (atau 88.59%)
-   Precision (untuk Kelas 1 - Ada Penyakit Jantung): 0.872 (atau 87.16%)
-   **Recall (untuk Kelas 1 - Ada Penyakit Jantung): 0.931 (atau 93.14%)**
-   **F1-score (untuk Kelas 1 - Ada Penyakit Jantung): 0.900 (atau 90.05%)**
-   Jumlah Pasien Sakit yang Terlewat (False Negatives): 7


"""

# Confusion matrix heatmap
from sklearn.metrics import ConfusionMatrixDisplay

for name, model in models.items():
    y_pred = model.predict(X_test)
    disp = ConfusionMatrixDisplay.from_estimator(model, X_test, y_test, cmap='Blues', values_format='d')
    disp.ax_.set_title(f'Confusion Matrix: {name}')
    plt.show()

importances = best_rf.feature_importances_
indices = np.argsort(importances)[::-1]
features = X.columns

plt.figure(figsize=(10,6))
sns.barplot(x=importances[indices], y=features[indices])
plt.title('Feature Importance (Best Random Forest)')
plt.show()

"""Diagram batang ini menunjukkan fitur-fitur yang digunakan untuk melatih model, diurutkan dari atas ke bawah berdasarkan seberapa besar pengaruhnya menurut model Random Forest terbaik. Batang yang lebih panjang berarti fitur tersebut dianggap lebih penting oleh model.

- Fitur yang paling penting (batang terpanjang di atas) adalah ST_Slope_Up. Ini berarti bagaimana bentuk segmen ST pada hasil EKG saat pasien berolahraga (khususnya jika bentuknya menanjak/'Up') sangat berpengaruh pada prediksi model.
- Fitur-fitur penting berikutnya secara berurutan adalah ST_Slope_Flat (segmen ST datar), Oldpeak (nilai depresi ST), MaxHR (denyut jantung maksimum), Cholesterol (kadar kolesterol), ExerciseAngina_Y (apakah ada nyeri dada saat olahraga), Age (usia), dan seterusnya hingga fitur dengan pengaruh terkecil di bagian bawah.


Kesimpulan:

Model Random Forest terbaik menganggap bahwa karakteristik dari segmen ST pada EKG (terutama ST_Slope_Up dan ST_Slope_Flat) serta nilai Oldpeak adalah faktor-faktor yang paling dominan dalam memprediksi risiko penyakit jantung. Ini memberikan petunjuk bahwa hasil pemeriksaan EKG terkait aktivitas fisik sangat krusial menurut model ini. Fitur lain seperti denyut jantung maksimum, kolesterol, dan adanya nyeri dada saat berolahraga juga memiliki kontribusi yang signifikan.
"""

import joblib


joblib.dump(best_rf, 'best_rf_model.pkl')

joblib.dump(scaler, 'scaler.pkl')

print("Model dan scaler berhasil disimpan.")

print("Urutan fitur saat training:", list(X_train.columns))

"""# **Interference**

Pada cell Ini saya melakukan sebuah test prediksi model dengan menggunakan data pasien dummy dan model ini berhasil memprediksi pasien tersebut
"""

import pandas as pd
import joblib

model = joblib.load('best_rf_model.pkl')
scaler = joblib.load('scaler.pkl')

dummy = pd.read_csv('/content/dummy_patient_inference_fixed.csv')

num_features = ['Age', 'RestingBP', 'Cholesterol', 'MaxHR', 'Oldpeak']
dummy[num_features] = scaler.transform(dummy[num_features])

prediksi = model.predict(dummy)
print("Prediksi penyakit jantung pada pasien dummy:", "Ada" if prediksi[0]==1 else "Tidak ada")